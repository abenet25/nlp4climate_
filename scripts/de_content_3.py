import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import os
import pandas as pd
from pathlib import Path
from gensim.models import LdaModel, Word2Vec
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.exceptions import NotFittedError
from sklearn.utils.validation import check_is_fitted
from NLP_functions import (
    load_dict_and_corpus, 
    generate_wordcloud, 
    generate_topic_wordcloud,
    generate_topic_bar_chart,
    plot_word_vectors
)

# ğŸ“‚ Base path = wo main.py wird durchgefÃ¼hrt
BASE_PATH = Path().resolve()
DATA_PATH = BASE_PATH / "Data"
MODELS_PATH = BASE_PATH / "models"


# Datenstrukturen laden
corpus_paths = {
    "Wissenschaft": {
        "dict": str(DATA_PATH / "lda_dictionary_academia.dict"),
        "corpus": str(DATA_PATH / "lda_corpus_academia.mm")
    },
    "Institutionen": {
        "dict": str(DATA_PATH / "lda_dictionary_institutions.dict"),
        "corpus": str(DATA_PATH / "lda_corpus_institutions.mm")
    }, 
    "Medien": {
        "dict": str(DATA_PATH / "lda_dictionary_media.dict"),
        "corpus": str(DATA_PATH / "lda_corpus_media.mm")
    }
}

lda_models = {
    "Wissenschaft": LdaModel.load(str(DATA_PATH / "lda_models_academia.model")),
    "Institutionen": LdaModel.load(str(DATA_PATH / "lda_models_institutions.model")),
    "Medien": LdaModel.load(str(DATA_PATH / "lda_models_media.model"))
}

# Klassifikator: Vectorizer und Modelle
@st.cache_resource
def load_classification_models():
    with open(MODELS_PATH / "vectorizer.pkl", "rb") as f1, \
         open(MODELS_PATH / "logistic_regression.pkl", "rb") as f2, \
         open(MODELS_PATH / "naive_bayes.pkl", "rb") as f3:
        return pickle.load(f1), pickle.load(f2), pickle.load(f3)


def show_de_content():
    # Titel
    st.markdown("<h3 style='margin-bottom: 0;'>ğŸŒ Lebenserwartung und Klimawandel mit NLP</h3>", unsafe_allow_html=True)
    st.markdown("<h4 style='margin-top: 0;'>Word-Clouds, Themenvisualisierung, Satzklassifikation</h4>", unsafe_allow_html=True)

    # Navigation
    st.sidebar.title("ğŸ§­ Navigation")
    option = st.sidebar.radio(
        "WÃ¤hle eine Sektion:",
        ("ğŸ“˜Projektbeschreibung", 
         "ğŸ“² Daten und Methodologie", 
         "ğŸ—‚ï¸ Themenvisualisierung", 
         "ğŸ§  Satzklassifikation", 
         "ğŸš€ Verbesserungspotenziale", 
         "ğŸ“‹ Ãœber das Projekt")
    )

    if option == "ğŸ“˜Projektbeschreibung":
        show_project_description()
    elif option == "ğŸ“² Daten und Methodologie":
        show_data_methodology()
    elif option == "ğŸ—‚ï¸ Themenvisualisierung":
        show_topic_visualization()
    elif option == "ğŸ§  Satzklassifikation":
        show_sentence_classification()
    elif option == "ğŸš€ Verbesserungspotenziale":
        st.title("ğŸš€ Verbesserungspotenziale")
        st.markdown("""
        â†—ï¸ **Institutionelle und journalistische Korpus zu erweitern**  
        WÃ¤hrend zahlreiche akademische Texte bereits erfolgreich Ã¼ber eine API (Semantic Scholar) gesammelt wurden, 
        ist das Ziel, auf Ã¤hnliche Weise auch fÃ¼r institutionelle und journalistische Quellen geeignete Texte automatisiert 
        zu extrahieren â€“ z.B. per API oder Web Scraping.    
        Dies wÃ¼rde die Datenbasis vergrÃ¶ÃŸern und balancieren, und die Klassifikation verbessern. \n 
        ğŸ‘Œ **ErhÃ¶hung der SensitivitÃ¤t des Klassifikators**  
        Derzeit versucht das Modell, jeden Satz einer der drei vordefinierten Quellen (akademisch, institutionell oder journalistisch) zuzuordnen. 
        Eine mÃ¶gliche Verbesserung wÃ¤re die Integration eines Mechanismus, der erkennt, ob der eingegebene Satz zum thematischen Bereich 
        des Gesamtkorpus gehÃ¶rt. Dies wÃ¼rde ermÃ¶glichen, **eine Vorhersage Ã¼ber den Grad der PlausibilitÃ¤t des Satzes im gegebenen Kontext** abzugeben 
        und zu warnen, wenn dessen Inhalt signifikant vom ursprÃ¼nglichen Korpus abweicht. \n            
        ğŸ§± **Verbesserung der ModularitÃ¤t der internen Projektstruktur**    
        Die LÃ¤nge des Hauptscripts (de_content.py / ca_content.py) kann reduziert und besser verwaltet werden, 
        wenn die Funktionen in eigenstÃ¤ndige Module ausgelagert werden.  
        Auch die Struktur der Daten (Modelle, Korpora und WÃ¶rterbÃ¼cher) kÃ¶nnte neu organisiert werden,  
        um die Wartbarkeit und Skalierbarkeit zu verbessern.\n
        

        """)
    elif option == "ğŸ“‹ Ãœber das Projekt":
        st.title("ğŸ“‹ Ãœber das Projekt")
        st.markdown("""
        **Autorin:** Ariadna Benet  
        **Projekt durchgefÃ¼hrt im Rahmen des [Data Science Bootcamps â€“ Data Science Institute by Fabian Rappert](https://www.data-science-institute.de)**  
        **Jahr:** 2025  

        ğŸ“Š Datensatz als Ausgangspunkt: [Countries Life Expectancy (Kaggle)](https://www.kaggle.com/datasets/amirhosseinmirzaie/countries-life-expectancy)  
        ğŸ“š Bibliotheken: Streamlit, Gensim, scikit-learn, wordcloud, Matplotlib, NumPy, Pandas, Seaborn

        ğŸ”§ Dieses Projekt verwendet Techniken des Natural Language Processing (NLP), wie LDA, Word2Vec und supervised Klassifikatoren.
        """)

def show_project_description():
    st.markdown("<h2 style='margin-bottom: 0;'>ğŸ“˜Projektbeschreibung</h2>", unsafe_allow_html=True)
    st.markdown("""
    Willkommen zu unserem **Natural Language Processing (NLP) Projekt**!  
    Dieser Beitrag ist Teil des Abschlussprojekts **â€Lebenserwartung: Analysen mit Business Intelligence, Machine Learning 
    und Natural Language Processingâ€œ**, durchgefÃ¼hrt im Rahmen des **Data Science Bootcamps** am [Data Science Institute by Fabian Rappert](https://www.data-science-institute.de).

    ğŸ“Š **Datengrundlage**  
    Das Projekt basiert auf dem Datensatz ğŸ‘‰ [Countries Life Expectancy](https://www.kaggle.com/datasets/amirhosseinmirzaie/countries-life-expectancy) *(Kaggle)*.
    Auf diesem Datensatz basieren die Analysen mit Business Intelligence und Machine Learning. Es wird untersucht, welche Variablen 
    die Lebenserwartung auf allen Kontinenten am stÃ¤rksten beeinflussen. AuÃŸerdem werden Prognosen darÃ¼ber erstellt, wie sich die Werte 
    in AbhÃ¤ngigkeit von VerÃ¤nderungen der verschiedenen Faktoren entwickeln kÃ¶nnten.
                
    ğŸŒ **Forschungsfrage**  
    Nachdem die Daten zur Lebenserwartung analysiert wurden, **stellt sich die Frage, ob der Klimawandel die Lebenserwartung beeinflusst 
    â€“ oder beeinflussen kÃ¶nnte**.
    Welche Auswirkungen kÃ¶nnten globale PhÃ¤nomene wie Temperaturanstieg oder Luftverschmutzung auf die Lebensdauer haben?
    Sind diese Effekte in reichen und armen LÃ¤ndern gleich stark?
    Und haben eher lokale Folgen des Klimawandels â€“ wie Naturkatastrophen â€“ bereits erkennbare Spuren in der Lebenserwartung hinterlassen?
    KÃ¶nnte es sein, dass entwickelte LÃ¤nder kÃ¼nftig stÃ¤rker vom Klimawandel betroffen sind als von bestimmten Krankheiten? 

    ğŸ”­ Ansatz    
    Da es schwierig ist, numerische DatensÃ¤tze aus beiden Bereichen direkt miteinander zu verknÃ¼pfen, wÃ¤hlen wir einen alternativen Ansatz:
    Wir analysieren Texte zu beiden Themenbereichen mithilfe von Methoden des maschinellen Lernens, um unsere Forschungsfragen zu beantworten.
                
    ğŸ¯ **Zielsetzung**  
    Unser Ziel ist es, **das Thema Lebenserwartung mit dem des Klimawandels zu verknÃ¼pfen**, indem wir **englischsprachige Texte** 
    zu beiden Themen aus **drei unterschiedlichen Quellen** analysieren:

    - ğŸ‘©â€ğŸ« Akademische Publikationen  
    - ğŸ›ï¸ Institutionelle Berichte  
    - ğŸ“° Journalistische Artikel  
    
    ğŸ—‚ï¸ Wir untersuchen die hÃ¤ufigsten Themen in Texten aus diesen drei Quellen.  
    ğŸ§  Wir trainieren einen Satzklassifikator, der vorhersagt, aus welcher dieser drei Quellen ein gegebener Satz stammt.

    âš™ï¸ **Methodologie**  
    Durch **Themenmodellierung** (*Topic Modeling*), **semantische Wortdarstellungen** (*Word Embeddings*) und **Klassifikationsverfahren** 
    (mit *Multinomial Naive Bayes* und logistischer Regression) gewinnen wir Einblicke in die sprachliche Darstellung dieser globalen Themen.   
    Da numerische DatensÃ¤tze aus beiden Bereichen schwer zu verknÃ¼pfen sind,  
    **wandeln wir Texte und WÃ¶rter in Vektoren und Zahlen um**.
                

    """, unsafe_allow_html=True)

def show_data_methodology():
    st.markdown("<h2 style='margin-bottom: 0;'>ğŸ“² Daten und Methodologie</h2>", unsafe_allow_html=True)
    # Daten
    st.subheader("ğŸ” DatenÃ¼bersicht")
    st.markdown("""
    Die Korpora wurden mit API / manuell zusammengestellt und bereinigt. Insgesamt analysieren wir:

    - 432 wissenschaftliche Abstracts (API Semantic Scholar)
    - 22 institutionelle Berichte (WHO, UN, World Bank)
    - 29 journalistische Artikel (BBC, Euronews, Reuters, The Conversation, u.a.)
                
    SuchwÃ¶rter: "life expectancy" AND "climate change"; "health" AND "climate change"
    
    Optimierungsziel: Zur besseren Ausbalancierung der drei Quellen sollen die institutionellen 
    und journalistischen Korpora erweitert werden â€“idealerweise durch automatisiertes Scraping 
    mithilfe von APIs (siehe ğŸš€ Verbesserungspotenziale). 

    Wir arbeiten mit insgesamt Ã¼ber **154.000 WÃ¶rtern**.
    """)
 
    # Daten
    labels = ["Wissenschaft", "Institutionen", "Media"]
    sizes = [96909, 29716, 27720]
    colors = ["#66b3ff", "#99ff99", "#ffcc99"]
    total = sum(sizes)

    # Bargraph
    fig, ax = plt.subplots(figsize=(4, 1.8))  

    bars = ax.barh(labels, sizes, color=colors)
    ax.set_xlabel("Anzahl der WÃ¶rter", fontsize=8)
    ax.set_title("Verteilung der Korpora nach Quellen", fontsize=8)

    # Werte neben die Bars
    for bar, count in zip(bars, sizes):
        percent = count / total * 100
        text = f"{count:,} ({percent:.1f}%)".replace(",", ".") 
        ax.text(count + total * 0.01, bar.get_y() + bar.get_height()/2,
                text, va='center', fontsize=7)

    # Format
    ax.tick_params(axis='both', labelsize=7)
    ax.set_xlim(0, max(sizes)*1.15)
    fig.tight_layout(pad=1)

    st.pyplot(fig)

    # Prozent und absolute Werte
    def make_autopct(values):
        def my_autopct(pct):
            total = sum(values)
            val = int(round(pct * total / 100.0))
            return f"{pct:.1f}%\n({val:,} WÃ¶rter)".replace(',', 'X').replace('.', ',').replace('X', '.')
        return my_autopct


    # Methoden
    st.subheader("âš™ï¸ Methoden & Vorgehen")
    st.markdown("""
    Folgende Schritte wurden durchgefÃ¼hrt:

    1. **Preprocessing**: Kleinschreibung, Entfernung von Sonderzeichen und Trennlinien.
    AuÃŸerdem fÃ¼r jeden Teil spezifisch: 
    
        
    | Modul              | Tokenisierung     | Analyse-Einheit | Bigrams | Stopwords                                 | Label |
    |-------------------|-------------------|------------------|---------|--------------------------------------------|--------|
    | **Word Cloud**     | âœ…                | Wort             | âœ…      | Englisch, SchlÃ¼sselwÃ¶rter, korpusspezifisch | âŒ     |
    | **LDA**            | âœ…                | Wort             | âœ…      | Englisch, SchlÃ¼sselwÃ¶rter, korpusspezifisch | âŒ     |
    | **Word2Vec**       | âœ…                | Wort             | âœ…      | Englisch, korpusspezifisch                | âŒ     |
    | **Klassifikation** | âœ…                | Satz             | âŒ      | keine                                     | âœ…     |

    """)           
    with st.expander("âœ‚ï¸ Was heiÃŸt *Tokenisierung*?"):
        st.write("""**Tokenisierung** ist der erste Schritt in der automatisierten Textverarbeitung im Bereich des Natural Language Processing (NLP). 
                \nDabei werden Texte in kleinere Einheiten â€“ sogenannte Tokens â€“ zerlegt. Diese Einheiten, hÃ¤ufig WÃ¶rter oder SÃ¤tze, bilden die Grundlage fÃ¼r die weitere Analyse.
                 """)

    with st.expander("ğŸ‘¯â€â™€ï¸ Was ist ein *Bigram*?"):
        st.write("""Ein **Bigram** ist ein hÃ¤ufig vorkommendes Paar von aufeinanderfolgenden WÃ¶rtern in einem Text. Zusammen bilden sie eine feste Bedeutungseinheit.
                 \n**Beispiel:** Das Wortpaar "air pollution" ist ein Bigram, da diese beiden WÃ¶rter oft zusammen verwendet werden und gemeinsam *Luftverschmutzung* bedeuten.
                """)
        
    with st.expander("ğŸ«¸ Was sind *Stopwords*?"):
        st.write("""**StopwÃ¶rter** sind hÃ¤ufig vorkommende WÃ¶rter wie "und", "der" oder "ist", die meist keinen wichtigen Beitrag zum Inhalt eines Textes leisten und deshalb bei der Analyse oft weggelassen werden.
                 \nğŸ”¹**Enlisch:** FÃ¼r jede Sprache werden spezifische Stoppwortlisten verwendet. Dabei handelt es sich meist um FunktionswÃ¶rter, wie zum Beispiel im Englischen "the", "is", "and" usw.    
                ğŸ”¹**SchlÃ¼sselwÃ¶rter:** Spezifische Begriffe, die thematisch zentral, aber zu dominant sind â€“ z.B. "health", "climate change" (SuchwÃ¶rter) â€“ werden entfernt, um Verzerrung in WordClouds oder LDA-Themen zu vermeiden.    
                ğŸ”¹**Korpusspezifisch:** Individuelle Liste basierend auf HÃ¤ufigkeitsanalysen im jeweiligen Korpus â€“ dient dazu, WÃ¶rter zu entfernen, die dort zwar oft vorkommen, aber analytisch wenig Mehrwert bieten. 
                 FÃ¼r das wissenschaftliche Korpus, z.B. "study", "analysis" oder "conclusions".
                  """)

    st.markdown("""
    
    2. **Unsupervised Learning** (d.h., ohne Label):  
    - **Word Cloud** pro Korpus  
    - **LDA-Themenmodellierung** fÃ¼r Themenvisualisierung
    - **Word2Vec** auf gesamten Korpus
    3. **Supervised Learning** (d.h., mit Label):  
    - Klassifikation von SÃ¤tzen: **Multinomial Naive Bayes** vgl. **Logic Regression**
    - Nutzer*in kann einen Satz eingeben und erhÃ¤lt die **wahrscheinlichste Quelle** (Wissenschaft, Institution oder Medien)
    """)

def show_topic_visualization():
    st.title("ğŸ—‚ï¸ Themenvisualisierung")
    st.markdown("""
    Hier zeigen wir die wichtigsten Themen jedes Korpus mit:
    
    - ğŸ”  **Word Clouds**  
    - ğŸ“Š **LDA-Topic modelling** 
    - ğŸ“ **Word2Vec**
    """)

    st.subheader("ğŸ”  **Word Clouds**")
 
    # Auswahl des Korpuses
    corpus_choice = st.selectbox(
        "WÃ¤hle einen Korpus aus:",
        list(lda_models.keys()),
        key="lda_corpus"
    )

    # Load WÃ¶rterbuch und Korpus
    path_dict = corpus_paths[corpus_choice]["dict"]
    path_corpus = corpus_paths[corpus_choice]["corpus"]
    dictionary, corpus = load_dict_and_corpus(path_dict, path_corpus)

    # LDA model corresponent
    lda_model = lda_models[corpus_choice]

    # Word Cloud generieren und zeigen
    with st.expander(f"Word Cloud des Korpus: {corpus_choice}", expanded=True):
        wc = generate_wordcloud(dictionary, corpus)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig)

    # Funktion zur Generierung der Thema-Bezeichnungen
    def get_topic_labels(lda_model, topn=1):
        labels = []
        for i in range(lda_model.num_topics):
            top_words = lda_model.show_topic(i, topn=topn)
            main_word = top_words[0][0]
            labels.append((i, f"Thema {i+1} â€“ {main_word}"))
        return labels
    
    # Themenliste aufbauen
    topic_labels = get_topic_labels(lda_model)
    label_to_id = {label: idx for idx, label in topic_labels}

    st.subheader("ğŸ“Š **LDA-Topic modelling**" )

    # Thema auswÃ¤hlen
    topic_label = st.selectbox(f"5 Top-Themen im Korpus {corpus_choice}", list(label_to_id.keys()), key="lda_topic")
    topic_id = label_to_id[topic_label]

    col1, col2 = st.columns(2)
    with col1:
        wc_topic = generate_topic_wordcloud(lda_model, topic_id)
        fig_wc, ax_wc = plt.subplots(figsize=(12, 6))
        ax_wc.imshow(wc_topic, interpolation='bilinear')
        ax_wc.axis('off')
        st.pyplot(fig_wc)
    with col2:
        fig_bar = generate_topic_bar_chart(lda_model, topic_id)
        st.pyplot(fig_bar)
    
    st.markdown("""
    Diese Themen wurden mit einem LDA-Modell aus dem Korpus extrahiert.  
    Jedes Thema besteht aus WÃ¶rtern, die hÃ¤ufig zusammen im gleichen Kontext auftreten.  
    Manchmal erscheint dasselbe Wort in mehreren Themen einer einzelnen Gruppe.  
    Das liegt daran, dass dieses Wort im Korpus insgesamt sehr hÃ¤ufig vorkommt und auch in verschiedenen thematischen ZusammenhÃ¤ngen eine wichtige Rolle spielt.  
    LDA: "Latent Dirichlet Allocation".
    """)    

    st.subheader("ğŸ“ **Word2Vec:** Semantische Wortbeziehungen entdecken")

    st.markdown("""
    **Word2Vec** ist ein Modell, das WÃ¶rter als numerische Vektoren darstellt, 
    basierend auf ihren semantischen Kontexten im Textkorpus.
    Diese Vektoren haben typischerweise eine hohe Dimension (z.B. 100),  
    werden aber mithilfe einer **PCA** (Hauptkomponentenanalyse) auf zwei Dimensionen reduziert,  
    um sie besser visualisieren zu kÃ¶nnen. 
    Dadurch lassen sich Beziehungen zwischen Begriffen identifizieren 
    und anschaulich im zweidimensionalen Raum darstellen.
    
    ğŸ“ In der folgenden Grafik sieht man eine PCA-Projektion dieser Vektoren.
    Je nÃ¤her zwei Punkte beieinander liegen, desto Ã¤hnlicher wurden sie vom Modell verstanden.
    
    """)

    # Modell laden
    @st.cache_resource
    def load_model():
        return Word2Vec.load("models/word2vec_global.model")
    
    model_w2v = load_model()

    # ğŸŒ PCA-Visualisierung

    input_words = st.text_input(
        "WÃ¶rter zum Visualisieren (durch Leerzeichen getrennt):",
        "climate_change life_expectancy health air_pollution policy"
    )

    words_list = input_words.strip().split()
    words_checked = [w.lower().strip() for w in input_words.strip().split()]
    words_found = [w for w in words_checked if w in model_w2v.wv]
    words_not_found = [w for w in words_checked if w not in model_w2v.wv]

    # Wenn kein Word im Modell
    if not words_found:
        st.error("âš ï¸ Keine der eingegebenen WÃ¶rter ist im Modell vorhanden.")
    else:
        # Einige WÃ¶rter sind nicht im Modell
        if words_not_found:
            st.warning(f"âš ï¸ Folgende WÃ¶rter sind **nicht** im Modell enthalten und wurden ignoriert: {', '.join(words_not_found)}")
        
        # Visualisierung fÃ¼r die gefundene WÃ¶rter
        fig = plot_word_vectors(model_w2v, words_found)
        if fig:
            st.pyplot(fig)

def show_sentence_classification():
    st.title("ğŸ§  Klassifizierung von SÃ¤tzen")
    st.markdown("""
    Gib unten einen beliebigen Satz Ã¼ber Lebenserwartung und Klimmawandel auf Englisch ein und unser Modell sagt dir voraus,
    ob der aus einem **wissenschaftlichen**, **institutionellen** oder **journalistischen** Text stammt.     
    Probiere zum Beispiel mit: "Climate change affects life expectancy"; anschlieÃŸend fÃ¼ge "in Europe" hinzu.
    """)

    vectorizer, model_lr, model_nb = load_classification_models()

    try:
        check_is_fitted(vectorizer, "idf_")
    except NotFittedError:
        st.error("âŒ Der Vektorisierer wurde nicht trainiert. Bitte Ã¼berprÃ¼fe die Datei 'vectorizer.pkl'.")
        st.stop()
        
    # Benutzereingabe
    user_input = st.text_input("âœï¸ Satz eingeben:")

    if user_input:
        # In Vektoren umwandeln und vorhersagen
        X_input = vectorizer.transform([user_input])
        pred = model_lr.predict(X_input)[0]
        probas = model_lr.predict_proba(X_input)[0]
        classes = model_lr.classes_

        st.success(f"Modellvorhersage: **{pred}**")

        # Wahrscheinlichkeiten anzeigen
        st.markdown("### ğŸ² Wahrscheinlichkeiten:")
        for label, prob in zip(classes, probas):
            st.write(f"â€¢ **{label}**: {prob * 100:.1f}%".replace('.', ','))
        
        # Barchart der Wahrscheinlichkeit

        import matplotlib.ticker as mtick

        proba_df = pd.DataFrame({"Klasse": classes, "Wahrscheinlichkeit": probas})
        proba_df = proba_df.sort_values("Wahrscheinlichkeit", ascending=True)

        fig, ax = plt.subplots(figsize=(3, 1.2))
        ax.barh(proba_df["Klasse"], proba_df["Wahrscheinlichkeit"], color="skyblue")
        ax.set_xlim(0, 1)
        ax.set_xlabel("Wahrscheinlichkeit", fontsize=4)
        ax.set_title("Verteilung der Klassifikation", fontsize = 5)
        ax.tick_params(axis='both', labelsize=5)
        ax.xaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f"{x:.1f}".replace('.', ',')))
        fig.tight_layout(pad=1)
        st.pyplot(fig)

        # Vergleich Multinomial Naive Bayes - Logistic Regression
        st.markdown("## ğŸ¤– Modellauswahl fÃ¼r die Klassifizierung")
        st.markdown(""" ZunÃ¤chst wurde das Modell **Multinomial Naive Bayes** angewendet.
                    Da die **Accuracy** jedoch mit **67,56%** relativ niedrig ausfiel und 
                    vor allem viele SÃ¤tze der Kategorie *academic* zugeordnet wurden (s. *Confusion Matrix*), 
                    wurde angenommen, dass dieses Modell stÃ¤rker von der **ÃœberreprÃ¤sentation 
                    akademischer SÃ¤tze** beeinflusst ist.""")
        st.markdown("""Aus diesem Grund wurde zusÃ¤tzlich **Logistic Regression** getestet.
                    Dieses Modell lieferte nicht nur eine hÃ¶here **Accuracy** von **75,35%**, 
                    sondern auch deutlich **ausgewogenere Ergebnisse** in Bezug auf *Precision*, 
                    *Recall* und *F1-Score*, insbesondere bei den Klassen *institutional* und *media*.
                    Daher wurde **Logistic Regression** fÃ¼r die finale Klassifikation bevorzugt.""")
        
        st.markdown("### Confusion Matrix:")

        with open("models/naive_bayes.pkl", "rb") as f:
            nb_model = pickle.load(f)

        with open("models/logistic_regression_tr.pkl", "rb") as f:
            lr_model = pickle.load(f)

        with open("models/X_test_tfidf.pkl", "rb") as f1, open("models/y_test.pkl", "rb") as f2:
            X_test_tfidf = pickle.load(f1)
            y_test = pickle.load(f2)

        nb_preds = nb_model.predict(X_test_tfidf)
        lr_preds = lr_model.predict(X_test_tfidf)   
           
        def plot_confusion_matrix(y_true, y_pred, labels, title):
            cm = confusion_matrix(y_true, y_pred, labels=labels)
            fig, ax = plt.subplots(figsize=(2, 2))
            heatmap = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                        square= True,
                        xticklabels=labels, yticklabels=labels, 
                        annot_kws={"size": 5}, ax=ax, 
                        cbar_kws={"shrink": 0.5})
            cbar = heatmap.collections[0].colorbar
            cbar.ax.tick_params(labelsize=5)
            
            ax.set_title(title, fontsize=6)
            ax.set_xlabel("Predicted", fontsize=5)
            ax.set_ylabel("Actual", fontsize=5)
            ax.tick_params(axis='both', labelsize=4)
            heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=0, fontsize=3)
            heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, fontsize=3)

            fig.tight_layout(pad=1)
            st.pyplot(fig)
        

        col1, col2 = st.columns(2)

        with col1:
            plot_confusion_matrix(y_test, nb_preds, labels=classes, title="Naive Bayes")

        with col2:
            plot_confusion_matrix(y_test, lr_preds, labels=classes, title="Logistic Regression")   


        st.markdown("### Classification Reports:")

        
        def classification_report_to_df(report_str):
            lines = report_str.strip().split("\n")
            data = []
            for line in lines[2:-3]:
                parts = line.strip().split()
                if len(parts) == 5:
                    label = parts[0]
                    precision, recall, f1, support = map(float, parts[1:])
                    data.append((label, precision, recall, f1, int(support)))
            return pd.DataFrame(data, columns=["Label", "Precision", "Recall", "F1-Score", "Support"])

        def style_report_table(df):
            return (
                df.style
                .format({"Precision": "{:.2f}", "Recall": "{:.2f}", "F1-Score": "{:.2f}"})
                .set_properties(subset=["Precision", "Recall", "F1-Score", "Support"], **{"text-align": "right"})
                .set_table_styles([
                    {"selector": "th", "props": [("text-align", "right")]},  # AlineaciÃ³ de capÃ§aleres
                ])
            )

        report_nb_str = classification_report(y_test, nb_preds, target_names=model_nb.classes_)
        report_lr_str = classification_report(y_test, lr_preds, target_names=lr_model.classes_)

        report_nb_df = classification_report_to_df(report_nb_str)
        report_lr_df = classification_report_to_df(report_lr_str)

        # Calcular l'accuracy manualment
        accuracy_nb = accuracy_score(y_test, nb_preds)
        accuracy_lr = accuracy_score(y_test, lr_preds)

        st.markdown("#### Multinomial Naive Bayes")
        st.markdown(f"â¡ï¸ **Accuracy**: {accuracy_nb:.2%}")
        st.dataframe(style_report_table(report_nb_df))

        st.markdown("#### Logistic Regression ğŸ… ")
        st.markdown(f"â¡ï¸ **Accuracy**: {accuracy_lr:.2%}")
        st.dataframe(style_report_table(report_lr_df))
